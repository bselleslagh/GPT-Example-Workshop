{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser, os\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#import tiktoken\n",
    "\n",
    "# Set the API key and load the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "openai.api_key = config['openai']['api_key']\n",
    "os.environ['OPENAI_API_KEY'] = config['openai']['api_key']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fine-Tuning\n",
    "In this notebook we will retrain the model by fine-tuning GPT-3 with an example dataset.\n",
    "We can then ask questions to the model related to the dataset we just fine-tuned it with.\n",
    "\n",
    "![Model Selection](../images/fine_tuning_model_selection.png)\n",
    "\n",
    "\n",
    "*Illustrative examples of text classification performance on the Stanford Natural Language Inference (SNLI) Corpus, in which ordered pairs of sentences are classified by their logical relationship: either contradicted, entailed (implied), or neutral. Default fine-tuning parameters were used when not otherwise specified.*\n",
    "\n",
    "For complex tasks, requiring subtle interpretation or reasoning or prior knowledge or coding ability, the performance gaps between models can be larger, and better models like curie or text-davinci-002 could be the best fit.\n",
    "\n",
    "**A single project might end up trying all models. One illustrative development path might look like this:**\n",
    "- Test code using the cheapest & fastest model (ada)\n",
    "- Run a few early experiments to check whether your dataset works as expected with a middling model (curie)\n",
    "- Run a few more experiments with the best model to see how far you can push performance (text-davinci-002)\n",
    "- Once you have good results, do a training run with all models to map out the price-performance frontier and select the model that makes the most sense for your use case  (ada, babbage, curie, davinci, text-davinci-002)\n",
    "\n",
    "**Another possible development path that uses multiple models could be:**\n",
    "- Starting with a small dataset, train the best possible model (text-davinci-002)\n",
    "- Use this fine-tuned model to generate many more labels and expand your dataset by multiples\n",
    "- Use this new dataset to train a cheaper model (ada)\n",
    "\n",
    "\n",
    "More info about model fine-tuning can be found [here](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#).\n",
    "\n",
    "In this notebook we will fine-tune the model with FAQ data coming from https://coolblue.be. We will then ask questions to the model related to the dataset we just fine-tuned it with.\n",
    "\n",
    "## Step 1: Preprocess the FAQ data\n",
    "The preprocessing step is crucial for ensuring that the FAQ data is in a format that can be easily processed by the model. Here are some common preprocessing steps for text data:\n",
    "\n",
    "1. **Lowercase the text**: Converting all text to lowercase can help reduce the size of the vocabulary and make the model more robust to variations in capitalization.\n",
    "\n",
    "2. **Tokenize the text**: Tokenization involves splitting the text into individual tokens (e.g., words or subwords) that can be fed into the model. This can be done using a tokenizer, such as the one provided by the Hugging Face Transformers library.\n",
    "\n",
    "3. **Remove punctuation and special characters**: Removing punctuation and special characters can help reduce the size of the vocabulary and make the model more robust to variations in the input.\n",
    "\n",
    "4. **Remove stop words**: Stop words are common words that are unlikely to carry much meaning, such as \"a\", \"an\", \"the\", etc. Removing stop words can reduce the size of the vocabulary and improve the efficiency of the model.\n",
    "\n",
    "5. **Convert words to IDs**: The model operates on numbers, not words, so we need to convert each word in the text to a unique integer ID. This can be done using a vocabulary, which maps each word to an ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can pay online with Bancontact (card and app), credit card (Visa or MasterCard), PayPal, Apple Pay, Coolblue gift cards, or a bank transfer. In the store, you can easily pay with Bancontact, credit card, cash, Apple Pay, Coolblue gift cards, Consumption Passes, and EcoCheques.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question only when the answer is in the training data, and if you're unsure of the answer, say \"I can't help you with this, please contact customer support at support@coolblue.be\".\n",
    "\n",
    "Context:\n",
    "You can pay online with Bancontact (card and app), credit card (Visa or MasterCard), PayPal, Apple Pay, Coolblue gift cards, or a bank transfer.\n",
    "In the store, you can easily pay with Bancontact, credit card, cash, Apple Pay, Coolblue gift cards, Consumption Passes, and EcoCheques.\n",
    "\n",
    "Q: WWhat kind of payment methods are supported ?\n",
    "A:\"\"\"\n",
    "\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 rows in the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Invoices</th>\n",
       "      <th>Where can I find my invoice?</th>\n",
       "      <td>We always include the invoice in the shipping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can I have products delivered at a VAT rate of 0%?</th>\n",
       "      <td>No, it's not possible to order products at a V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warranty and repairs\\n</th>\n",
       "      <th>Can I have my product repaired in the store?</th>\n",
       "      <td>Yes, you can drop off your product in one of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Ordering</th>\n",
       "      <th>Can I pay afterwards?</th>\n",
       "      <td>Yes, via a credit card. When you place an orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What does Second Chance mean?</th>\n",
       "      <td>A Second Chance product is a product that has ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      Answer\n",
       "Title                  Subject                                                                                              \n",
       "Invoices               Where can I find my invoice?                        We always include the invoice in the shipping ...\n",
       "                       Can I have products delivered at a VAT rate of 0%?  No, it's not possible to order products at a V...\n",
       "Warranty and repairs\\n Can I have my product repaired in the store?        Yes, you can drop off your product in one of o...\n",
       "Ordering               Can I pay afterwards?                               Yes, via a credit card. When you place an orde...\n",
       "                       What does Second Chance mean?                       A Second Chance product is a product that has ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data_files/coolblue_faq.csv\")\n",
    "df = df.set_index([\"Title\",\"Subject\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.Answer) for idx, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.Title, r.Subject): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Warranty and repairs\\n', 'What type of warranty do I have?') : [0.018135065212845802, -0.005953091196715832, -0.010298511013388634, -0.01627850905060768, -0.035086240619421005]... (1536 entries)\n"
     ]
    }
   ],
   "source": [
    "# An example embedding:\n",
    "example_entry = list(document_embeddings.items())[0]\n",
    "print(f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have split our document library into sections, and encoded them by creating embedding vectors that represent each chunk. Next we will use these embeddings to answer our users' questions.\n",
    "\n",
    "# 2) Find the most similar document embeddings to the question embedding\n",
    "\n",
    "At the time of question-answering, to answer the user's query we compute the query embedding of the question and use it to find the most similar document sections. Since this is a small example, we store and search the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/) or [Weaviate](https://github.com/semi-technologies/weaviate) to power the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8182337267862931, ('Ordering', 'Can I pay afterwards?')),\n",
       " (0.7814901015767994, ('Invoices', 'Where can I find my invoice?')),\n",
       " (0.7755437010341466,\n",
       "  ('Invoices', 'Can I have products delivered at a VAT rate of 0%?')),\n",
       " (0.7627375648790945, ('Invoices', \"What if I didn't receive an invoice?\")),\n",
       " (0.7482394073512559, ('Ordering', 'How do I cancel my order?'))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"What payment methods are available?\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8437506899031103,\n",
       "  ('Warranty and repairs\\n', 'What type of warranty do I have?')),\n",
       " (0.8123131144105407, ('Warranty and repairs\\n', 'Is my repair free?')),\n",
       " (0.7774787621501347,\n",
       "  ('Warranty and repairs\\n', 'Can I have my product repaired in the store?')),\n",
       " (0.740717769143366, ('Ordering', 'What does Second Chance mean?')),\n",
       " (0.7406376137237811, ('Ordering', 'Can I pay afterwards?'))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"What types of warranty are there ?\", document_embeddings)[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Add the most relevant document sections to the query prompt\n",
    "\n",
    "Once we've calculated the most relevant pieces of context, we construct a prompt by simply prepending them to the supplied query. It is helpful to use a query separator to help the model distinguish between separate pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n* \"\n",
    "ENCODING = \"gpt2\"  # encoding for text-davinci-003\n",
    "\n",
    "encoding = tiktoken.get_encoding(ENCODING)\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
